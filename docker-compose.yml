
x-base: &x-base
  init: true
  environment:
    - LOG_LEVEL=INFO
  volumes:
    - ./diffusert:/workspace/diffusert/
    - ~/.cache/huggingface:/root/.cache/huggingface
  working_dir: /workspace/diffusert

x-gpu: &x-gpu
  deploy:
    resources:
      reservations:
        devices:
          - driver: nvidia
            capabilities: ["gpu"]

services:
  whisper:
    <<: *x-gpu    
    image: onerahmet/openai-whisper-asr-webservice:latest-gpu
    environment:
      - ASR_MODEL=small
    profiles:
      - speech

  certbot:
    image: certbot/certbot:latest
    profiles:
      - letsencrypt
    volumes:
      - ./certbot/www/:/var/www/certbot/:rw
      - ./certbot/conf/:/etc/letsencrypt/:rw

  frontend-build:
    image: node:21-alpine
    working_dir: /app
    volumes:
      - ./client:/app
    command: "sleep infinity"
    profiles:
      - build

  frontend: &frontend
    image: nginx
    volumes:
      - ./client/out/:/usr/share/nginx/html
      - ./configs/nginx.conf:/etc/nginx/templates/default.conf.template
      - ./certbot/www/:/var/www/certbot/:ro
      - ./certbot/conf/:/etc/letsencrypt/:ro
    ports:
      - 80:80
      - 443:443
    environment:
      - BACKEND_HOST=backend
    profiles:
      - production

  frontend-dev:
    <<: *frontend
    environment:
      - BACKEND_HOST=backend-dev
    profiles:
      - ''
      - dev

  backend: &backend
    <<: [*x-base,*x-gpu]

    build: .
    entrypoint: "python3 server.py"
    shm_size: 50g
    expose:
      - 8080
    profiles:
      - production
  
  backend-dev:
    <<: *backend
    image: videosd-backend
    entrypoint: "sleep infinity"
    profiles:
      - ''
      - dev

  coturn:
    image: coturn/coturn
    network_mode: host
    volumes:
      - ./configs/turnserver.conf:/etc/coturn/turnserver.conf
    environment:
      - DETECT_EXTERNAL_IP=no
      - DETECT_RELAY_IP=no
      - DETECT_EXTERNAL_IPV6=no
      - DETECT_RELAY_IPV6=no
